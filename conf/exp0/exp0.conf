name = exp0
debug = False
training_data = data/web-tagged.gz
output_dir = conf/exp0/output
min_test_features = 0.01
min_train_features = 1.0

[feature_extraction]
    min_df = 1
    k = 30
    lemmatize = True
    use_pos = True
    coarse_pos = True
    normalise_entities = False
    use_tfidf = False
    record_stats = False
    sim_compressor = eval.utils.misc.one
    decode_token_handler = eval.pipeline.feature_handlers.SignifiedOnlyFeatureHandler
    remove_features_with_NER = True
    random_neighbour_thesaurus = False
    [[train_time_opts]]
        extract_unigram_features = J, N    # V
        extract_phrase_features = AN, NN    # VO, SVO
    [[decode_time_opts]]
        extract_unigram_features = ,    # J,N,V or a single comma to indicate nothing
        extract_phrase_features = AN, NN    # VO, SVO

[tokenizer]
    lowercase = True
    remove_stopwords = True
    remove_short_words = False
    remove_long_words = True    # probably noise anyway.

[crossvalidation]
    type='skfold'
    k = 2
    break_after_first = False
    random_state = 0

[feature_selection]
    must_be_in_thesaurus = True

[classifiers]
    [[sklearn.naive_bayes.MultinomialNB]]
        run = True
        alpha = 0.001
    
    [[sklearn.linear_model.LogisticRegression]]
        run = True
        C = 1e-05

[vector_sources]
    sim_threshold = -9999999999.0    # we should be loading vectors here, so this is a reasonable threshold.
    neighbours_file = data/random_vectors.h5,
    max_neighbours = 2000000000
    allow_lexical_overlap = False
    use_shelf = False
    entries_of = ""
    neighbour_strategy = linear
    noise = 0.2
